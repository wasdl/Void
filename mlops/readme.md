# 정수기 데이터 DQM(Data Quality Management) 문서

## 1. 정수기 데이터 Feature 정의표

| Feature 이름 | 데이터 타입 | 유효 범위 | 설명 |
|-------------|------------|----------|------|
| person_id | BIGINT UNSIGNED | - | 사용자 번호 |
| time | DATETIME | - | 출수 시간 |
| output_seq | INT | 1 ~ 100 | 하루 내 출수 순서 |
| ratio_to_prev_day | FLOAT | 0 ~ 10 | 현재 시점 이전까지의 누적 출수량 / 이전날 총 출수량 |
| ratio_prev_to_total | FLOAT | 0 ~ 10 | 이전날 현재시간까지 마신 양 / 이전날 총 출수량 |
| time_diff_prev_outputs | TIME | 00:00 ~ 24:00 | 현재 출수 시간 - 이전 출수 시간 |
| prev_sum | INT | 0 ~ 10000 | 현재 시점 이전까지의 누적 출수량 |
| prev_day_mean | FLOAT | 0 ~ 10000 | 이전날 출수량의 평균 |
| prev_day_std | FLOAT | 0 ~ 10000 | 이전날 출수량의 표준편차 |
| prev_day_total | INT | 0 ~ 10000 | 이전날 출수량의 총 합 |
| slope_prev_day_n_n_minus_1 | INT | -10000 ~ 10000 | 이전날 같은 순서의 출수량과 그 이전 출수량의 차이 |
| slope_prev_day_n_minus_1_n_minus_2 | INT | -10000 ~ 10000 | 이전날 같은 순서의 출수량과 그 이전 출수량의 차이 와 이전날 같은 순서의 이전 출수량과 그 이전 시점의 출수량 차이 |
| avg_change_rate | FLOAT | 0 ~ 10000 | 이전날 그래프의 변화량 평균 |
| prev_output | INT | 0 ~ 10000 | 현재 시점 이전 번째의 출수량 |
| prev_prev_output | INT | 0 ~ 10000 | 현재 시점 이전의 이전 번째의 출수량 |

## 2. 정수기 데이터 ML 파이프라인

### 2.1 데이터 수집 및 전처리 단계

#### 2.1.1 홍분량 대비 덕 또는 증가량 기록 패턴 탐색

출수량 변화 패턴을 시계열 데이터로 수집하고, 사용자별 출수 행동 패턴을 탐색합니다.

| 단계 | 처리 방법 | 설명 |
|-----|----------|------|
| 1 | 원시 데이터 수집 | 사용자별 정수기 출수 시간 및 출수량 데이터 수집 |
| 2 | 시계열 패턴 생성 | 사용자별 출수 시간과 출수량을 시계열 형태로 구성 |
| 3 | 패턴 변동성 분석 | 일간/주간/월간 출수 패턴의 변동성 및 규칙성 분석 |

#### 2.1.2 DTW 기반 데이터 특성 생성

| 단계 | 처리 방법 | 설명 |
|-----|----------|------|
| 1 | 시계열 정규화 | 시계열 데이터의 스케일 정규화 및 누적 패턴 변환 |
| 2 | 패턴 유사도 계산 | DTW 알고리즘을 사용하여 시계열 패턴 간 유사도 계산 |
| 3 | 특성 벡터 생성 | DTW 거리 기반 특성 벡터 생성 |

#### 2.1.3 EDA 및 특성 검증 & 선택

| 단계 | 처리 방법 | 설명 |
|-----|----------|------|
| 1 | 탐색적 데이터 분석 | 데이터 분포, 결측치, 이상치 등 기본 특성 파악 |
| 2 | 특성 중요도 평가 | 특성별 중요도 평가 및 기여도 분석 |
| 3 | 특성 선택 | 모델 성능에 영향을 주는 주요 특성 선택 |

#### 2.1.4 데이터 품질 검증 기준

| 항목 | 처리 방법 | 설명 |
|-----|----------|------|
| 이상치(Outlier) | 제외 | Feature 정의표에 명시된 유효 범위를 벗어나는 데이터는 이상치로 간주하여 저장하지 않음 |
| 결측치(Missing Value) | 제외 | NULL 값이나 빈 값이 포함된 데이터는 결측치로 간주하여 저장하지 않음 |
| 중복 데이터 | 제거 | 동일 시간에 동일 사용자의 중복 데이터 제거 |
| 충분한 데이터량 | 검증 | 사용자별 최소 데이터 포인트 수 확인 (최소 30개 이상) |

### 2.2 패턴 분석 및 군집화 단계

#### 2.2.1 DBSCAN 기반 군집화 및 이상치 제거

| 단계 | 처리 방법 | 설명 | 중단 기준 |
|-----|----------|------|----------|
| 1 | DBSCAN 클러스터링 | 초기 데이터셋에 대해 DBSCAN 알고리즘을 사용하여 클러스터링 진행<br>(기본 파라미터: eps=0.9, min_samples=3) | - |
| 2 | 대표 군집 선정 | 실루엣 점수가 가장 높은 군집을 대표 군집으로 선정 | - |
| 3 | 대표 패턴 도출 | 대표 군집 내에서 다른 벡터들과의 DTW 거리가 가장 작은 벡터를 대표 패턴으로 선정 | - |
| 4 | DTW+IQR 이상치 제거 | 대표 패턴과 모든 데이터 간의 DTW 거리를 계산한 후, IQR 방식으로 임계값을 설정하여 이상치 제거 | - |
| 5 | 반복 클러스터링 | 이상치로 분류된 데이터에 대해 다시 DBSCAN 클러스터링을 반복 진행 | 1) 남은 유저 수가 전체의 5% 미만일 경우<br>2) 실루엣 점수가 0.5 미만일 경우 |

#### 2.2.2 Threshold 파라미터 자동 최적화

| 파라미터 | 조정 범위 | 설명 |
|---------|----------|------|
| eps | 0.3 ~ 1.5 | DBSCAN의 이웃 반경 값, 클러스터 밀도 결정 |
| min_samples | 2 ~ 10 | 코어 포인트 판별을 위한 최소 샘플 수 |
| IQR 계수 | 0.3 ~ 1.5 | IQR에 곱해지는 계수, 이상치 식별 기준 |

#### 2.2.3 DTW + IQR 이상치 처리 방법

DTW는 시계열 데이터의 유사성을 측정하는 알고리즘으로, 시간 축에서 왜곡된 두 시계열 데이터 간의 최적 정렬을 찾아 거리를 계산합니다. 이 DTW 거리를 기반으로 IQR 방식을 적용하여 이상치를 판별합니다.

| 항목 | 설명 |
|-----|------|
| 목적 | 출수 패턴의 시간적 변동성을 고려하여 유사하지 않은 패턴을 이상치로 식별 |
| 처리 과정 | 1. 대표 군집에서 중심 벡터 선정<br>2. 모든 데이터와 중심 벡터 간 DTW 거리 계산<br>3. 계산된 DTW 거리 분포에 IQR 방식 적용하여 이상치 판별 |
| 이상치 계산 | 1. Q1(25% 백분위수)과 Q3(75% 백분위수) 산출<br>2. IQR = Q3 - Q1 계산<br>3. 상한 경계 = Q3 + 0.5 * IQR 설정<br>4. DTW 거리가 상한 경계를 초과하는 데이터를 이상치로 분류 |
| 활용 | 이상치로 판별된 데이터를 제외한 나머지 데이터만 저장하여 후속 분석에 사용<br>제외된 이상치 데이터는 새로운 입력 데이터로 DBSCAN 클러스터링 과정 반복 적용 |

### 2.3 패턴 학습 및 분류 단계

#### 2.3.1 AutoEncoder 기반 대인 패턴 학습

클러스터링을 통해 군집화된 데이터로부터 오토인코더(AE)를 학습하여 각 군집의 대표 패턴을 생성하고 검증합니다.

| 항목 | 설명 | 구체적 설정 |
|-----|------|------------|
| 오토인코더 구조 | 48차원 입력 -> 24차원 은닉층 -> 12차원 잠재층 -> 24차원 은닉층 -> 48차원 출력 | - 인코더: Linear(48→24) → ReLU → Linear(24→12)<br>- 디코더: Linear(12→24) → ReLU → Linear(24→48) |
| 학습 파라미터 | 최적화 알고리즘, 손실 함수, 학습률, 에폭 등 | - 최적화: Adam<br>- 손실 함수: MSE<br>- 학습률: 0.001<br>- 에폭: 150 |
| 군집별 모델 | 각 군집(A, B, C 등)별로 별도의 오토인코더 모델 학습 | 군집별 데이터로만 학습하여 특성 보존 |
| 임계값 설정 | 각 군집별 재구성 오차(MSE)의 통계적 임계값 설정 | 재구성 오차의 평균 + 2.0 × 표준편차 (약 95% 신뢰구간) |

| 단계 | 처리 방법 | 설명 |
|-----|----------|------|
| 1 | 군집별 데이터 분리 | DBSCAN 클러스터링을 통해 얻은 각 군집별로 데이터 분리 |
| 2 | 오토인코더 학습 | 각 군집별로 오토인코더 모델 학습<br>(입력 패턴을 압축했다가 다시 복원하는 네트워크) |
| 3 | 주 패턴 생성 | 학습된 오토인코더의 디코더 부분을 활용하여 각 군집의 주요 패턴 생성 |
| 4 | 성능 검증 | 각 군집별 오토인코더의 재구성 정확도 평가 |

#### 2.3.2 AutoEncoder 기반 패턴 식별 (Classifier)

| 단계 | 처리 방법 | 설명 |
|-----|----------|------|
| 1 | 패턴 인코딩 | 입력 패턴을 오토인코더의 잠재 공간으로 인코딩 |
| 2 | 군집별 재구성 오차 계산 | 각 군집의 오토인코더로 입력 패턴 재구성 후 오차 측정 (MSE 사용) |
| 3 | 최적 군집 할당 | 재구성 오차가 가장 낮은 군집으로 패턴 분류 |
| 4 | 분류 신뢰도 산출 | 분류 결과의 신뢰도 점수 계산 (최소 오차 / 임계값) |

#### 2.3.3 패턴 X (이상 패턴) 및 패턴 O (정상 패턴) 식별

| 패턴 유형 | 식별 방법 | 처리 방식 |
|----------|----------|----------|
| 패턴 X (이상 패턴) | 모든 군집의 재구성 오차가 임계값 이상 | 이상 패턴으로 식별하여 별도 처리 |
| 패턴 O (정상 패턴) | 특정 군집의 재구성 오차가 임계값 이하 | 해당 군집의 패턴으로 분류하여 정상 처리 |
| 모델 할당 X | 분류 신뢰도가 낮은 경우 | 미할당 사용자로 분류하여 별도 관리 |

#### 2.3.4 Unknown 패턴 처리 프로세스

Unknown으로 분류된 패턴은 95% 신뢰구간 임계값을 초과한 패턴으로, 기존 군집에 적합하지 않은 패턴으로 판단됩니다.

| 단계 | 처리 방법 | 설명 |
|-----|----------|------|
| 1 | Unknown 패턴 식별 | 모든 군집의 재구성 오차가 임계값(평균 + 2.0 × 표준편차)을 초과하는 패턴 식별 |
| 2 | 첫 단계 처리 | Unknown으로 분류된 패턴을 가진 사용자 데이터를 다시 DBSCAN 클러스터링 과정으로 전달 |
| 3 | 재군집화 | Unknown 패턴 사용자들을 대상으로 군집화 파라미터를 조정하여 DBSCAN 재실행 |
| 4 | 신규 군집 생성 | 충분한 데이터가 모이면 새로운 군집 형성 및 파운데이션 모델 생성 |
| 5 | 주기적 재평가 | 7일 주기로 Unknown 패턴 사용자들의 데이터 축적 및 재평가 진행 |
| 6 | 특별 모니터링 | Unknown 사용자 비율이 전체의 5%를 초과할 경우 전체 클러스터링 파라미터 재조정 고려 |

#### 2.3.5 군집별 대인 패턴 평가

| 평가 지표 | 설명 | 목표 기준 |
|----------|------|----------|
| 군집 안정성 | 군집의 크기 및 일관성 평가 | 군집 크기 100명 이상, 실루엣 점수 0.45 이상 |
| 패턴 대표성 | 군집 내 패턴의 분산 및 대표성 평가 | 군집 내 DTW 거리 평균이 전체 평균의 50% 이하 |
| 시간적 안정성 | 시간 경과에 따른 군집 패턴 안정성 | 7일 간격 패턴 변화율 10% 이내 |

#### 2.3.6 오토인코더 정확도 측정 방법

| 측정 항목 | 측정 방법 | 목표 기준 |
|----------|----------|----------|
| 패턴별 정확도 | 1. 패턴별 전체 데이터 수 카운트<br>2. 패턴별 정확하게 분류된 데이터 수 카운트<br>3. 정확도 = 정확하게 분류된 데이터 수 / 전체 데이터 수 | 패턴별 최소 70% 이상 |
| Unknown 비율 | 1. 패턴별 전체 데이터 수 카운트<br>2. Unknown으로 분류된 데이터 수 카운트<br>3. Unknown 비율 = Unknown 데이터 수 / 전체 데이터 수 | 패턴별 최대 5% 이하 |
| 혼동 행렬 | 1. 예측된 패턴과 실제 패턴 간의 혼동 행렬 계산<br>2. Unknown을 제외한 정확도 측정 | 패턴 간 혼동 최소화 |
| 모델 성능 검증 | 1. Hold-out 검증: 학습 80%, 검증 20%로 분할<br>2. K-fold 교차 검증: 5-fold 교차 검증으로 안정성 확인 | 검증 세트에서 65% 이상 정확도 |

### 2.4 모델 구축 및 예측 단계

#### 2.4.1 추정 기반 예측 과정대인 모델 생성 (XGBoost)

클러스터링과 오토인코더 검증이 완료된 데이터를 기반으로 XGBoost 모델을 구축하여 최종 파운데이션 모델을 생성합니다.

| 단계 | 처리 방법 | 설명 |
|-----|----------|------|
| 1 | 전체 데이터 학습 | 모든 클러스터의 데이터를 통합하여 XGBoost 모델 학습 (ALL 모델) |
| 2 | K-Fold 교차 검증 | 5-Fold 교차 검증을 통한 모델 안정성 평가 |
| 3 | 성능 판단 | R2 점수 및 K-Fold 간 편차 확인 |
| 4-1 | 미달 시 조치 | R2 점수가 0.6 이하이거나 K-Fold 간 R2 점수 편차가 큰 경우 DBSCAN 클러스터링 재수행 요청 |
| 4-2 | 통과 시 진행 | ALL 모델을 임시 모델로 저장하고 클러스터별 모델링 단계로 진행 |

#### 2.4.2 클러스터별 모델 학습 및 튜닝

| 단계 | 처리 방법 | 설명 |
|-----|----------|------|
| 1 | 클러스터별 데이터 분리 | 각 클러스터(A, B, C...)별로 데이터 분리 |
| 2 | 개별 모델 학습 | 각 클러스터별로 XGBoost 모델 학습 |
| 3 | 하이퍼파라미터 튜닝 | 정확도가 65% 이상이 될 때까지 하이퍼파라미터 튜닝 수행 |
| 4 | 성능 검증 | 각 클러스터별 모델의 정확도, R2 점수, RMSE 등 검증 |
| 5 | 최종 모델 저장 | 각 클러스터별 최적화된 파운데이션 모델 저장 |

#### 2.4.3 하이퍼파라미터 튜닝 범위

| 파라미터 | 튜닝 범위 | 설명 |
|---------|----------|------|
| learning_rate | 0.01 ~ 0.3 | 학습률 (작을수록 정밀하나 학습 시간 증가) |
| max_depth | 3 ~ 10 | 트리 최대 깊이 (클수록 과적합 위험) |
| n_estimators | 100 ~ 1000 | 생성할 트리 개수 |
| subsample | 0.5 ~ 1.0 | 각 트리 구성에 사용할 샘플 비율 |
| colsample_bytree | 0.5 ~ 1.0 | 각 트리 구성에 사용할 특성 비율 |
| min_child_weight | 1 ~ 10 | 트리의 자식 노드를 생성하는데 필요한 최소 가중치 합 |

#### 2.4.4 파운데이션 모델 할당

| 단계 | 처리 방법 | 설명 |
|-----|----------|------|
| 1 | 사용자 패턴 분석 | 신규 또는 기존 사용자의 출수 패턴 분석 |
| 2 | 최적 군집 식별 | AutoEncoder 기반 분류기를 통해 최적 군집 식별 |
| 3 | 파운데이션 모델 할당 | 식별된 군집에 해당하는 파운데이션 모델 할당 |
| 4 | 모델 할당 검증 | 할당된 모델의 초기 예측 정확도 검증 |

### 2.5 개인화 및 최적화 단계

#### 2.5.1 개인화 모델 생성 프로세스

파운데이션 모델이 완성된 후, 개별 사용자의 데이터를 활용하여 개인화된 모델을 구축합니다.

| 단계 | 처리 방법 | 설명 |
|-----|----------|------|
| 1 | 사용자 분류 | 사용자 패턴 분석을 통해 적합한 클러스터 식별 및 해당 파운데이션 모델 할당 |
| 2 | 사용자 데이터 수집 | 사용자별 최대 100일 분량의 출수 데이터 수집 |
| 3 | 추가 학습 모델 생성 | 할당된 파운데이션 모델에 사용자 개인 데이터로 추가 학습 진행 |
| 4 | 개인 데이터 모델 생성 | 사용자 데이터만을 사용하여 별도의 XGBoost 모델 학습 |
| 5 | 앙상블 모델 구축 | 파운데이션 모델과 개인 데이터 모델을 가중치 기반으로 앙상블하여 최종 개인화 모델 생성 |

#### 2.5.2 앙상블 가중치 결정 방식

| 항목 | 설명 |
|-----|------|
| 가중치 결정 요소 | 사용자 데이터 양, 기존 파운데이션 모델과의 패턴 유사도, 개인 데이터 모델의 성능 |
| 가중치 조정 방식 | 사용자 데이터가 많을수록 개인 데이터 모델의 가중치 증가<br>파운데이션 모델: 개인 데이터 모델 = (1-α) : α<br>(α는 0.1~0.9 범위에서 데이터 양과 성능에 따라 결정) |
| 최적 가중치 탐색 | 교차 검증을 통해 최적의 앙상블 가중치 결정 |

#### 2.5.3 모델 선택 및 검증

| 단계 | 처리 방법 | 설명 |
|-----|----------|------|
| 1 | 성능 비교 | 1. 기존 파운데이션 모델<br>2. 추가 학습된 파운데이션 모델<br>3. 앙상블 개인화 모델<br>세 모델의 성능 비교 |
| 2 | 최종 모델 선택 | 검증 데이터에서 가장 높은 성능(R2 점수, 정확도)을 보이는 모델 선택 |
| 3 | 주기적 재평가 | 새로운 사용자 데이터 누적 시 모델 성능 재평가 및 필요 시 모델 업데이트 |
| 4 | 모델 저장 | 사용자별 최적 모델을 저장하여 실시간 예측에 활용 |

#### 2.5.4 개인화 모델 버전 관리 및 주기적 업데이트

| 항목 | 설명 |
|-----|------|
| 업데이트 주기 | 7일마다 새로운 사용자 데이터를 기반으로 모델 업데이트 |
| 버전 관리 | 사용자별 모델 버전 정보를 관리하여 모델 변경 이력 추적<br>(버전 형식: [사용자ID]_[군집ID]_[생성날짜]_v[버전번호]) |
| 성능 평가 | 새 버전과 기존 버전의 성능 비교 평가 (R2 점수, 정확도, RMSE) |
| 모델 선택 | 성능 지표가 더 우수한 모델을 최신 버전으로 등록하여 서비스에 적용 |
| 롤백 메커니즘 | 신규 모델 성능이 저하될 경우 이전 버전으로 자동 롤백 |

### 2.6 지속적 개선 및 확장 단계

#### 2.6.1 미할당 사용자 재분류 프로세스

파운데이션 모델이 할당되지 않은 사용자들을 위한 추가 모델 구축 프로세스입니다.

| 단계 | 처리 방법 | 설명 |
|-----|----------|------|
| 1 | 미할당 사용자 식별 | 기존 클러스터에 할당되지 않은 사용자 집합 식별 |
| 2 | 데이터 축적 | 미할당 사용자들의 출수 데이터 지속적 수집 |
| 3 | 새로운 DBSCAN 클러스터링 | 미할당 사용자 데이터에 대해 DBSCAN 알고리즘 적용<br>(필요시 파라미터 조정: eps, min_samples) |
| 4 | 신규 클러스터 검증 | 생성된 클러스터의 실루엣 점수 및 크기 평가 |
| 5 | 신규 파운데이션 모델 생성 | 검증 기준을 통과한 클러스터에 대해 새로운 XGBoost 파운데이션 모델 구축 |

#### 2.6.2 신규 클러스터 검증 기준

| 항목 | 기준 | 설명 |
|-----|------|------|
| 클러스터 크기 | 최소 사용자 수 100명 이상 | 충분한 학습 데이터 확보를 위한 최소 사용자 수 |
| 실루엣 점수 | 0.45 이상 | 클러스터 응집도와 분리도를 나타내는 지표 |
| 패턴 안정성 | IQR 기준 이상치 비율 20% 이하 | 대표 패턴과의 DTW 거리 기준 이상치 비율 |

#### 2.6.3 A/B 테스트 및 사용자 피드백 반영

| 단계 | 처리 방법 | 설명 |
|-----|----------|------|
| 1 | A/B 테스트 설계 | 모델 변형 및 개선사항에 대한 A/B 테스트 설계 |
| 2 | 사용자 그룹 분류 | 대조군과 실험군으로 사용자 그룹 분류 |
| 3 | 성능 측정 | 각 그룹의 모델 정확도 및 사용자 만족도 측정 |
| 4 | 피드백 수집 | 사용자 피드백 및 사용 패턴 변화 데이터 수집 |
| 5 | 모델 개선 적용 | 테스트 결과 및 피드백을 반영한 모델 개선사항 적용 |

#### 2.6.4 모델 저장소(Repository) 관리

| 항목 | 설명 |
|-----|------|
| 모델 저장 구조 | 파운데이션 모델과 개인화 모델을 체계적으로 관리하는 저장소 구조 |
| 버전 관리 | 모델 버전, 학습 데이터, 하이퍼파라미터, 성능 지표 등 메타데이터 관리 |
| 백업 정책 | 정기적인 모델 백업 및 복구 정책 |
| 접근 제어 | 모델 저장소에 대한 접근 권한 및 보안 관리 |

#### 2.6.5 모델 저장 형식 및 로드 방법

| 항목 | 설명 |
|-----|------|
| 오토인코더 모델 저장 | 각 패턴별 오토인코더 모델을 PyTorch state_dict 형태로 저장<br>파일명: autoencoder_{패턴}.pt |
| 임계값 저장 | 각 패턴별 재구성 오차 임계값을 pickle 형식으로 저장<br>파일명: thresholds.pkl |
| 모델 로드 | 1. 패턴별 오토인코더 로드 후 state_dict 적용<br>2. 임계값 pickle 파일 로드<br>3. 모델과 임계값을 활용한 예측 함수 초기화 |
| 디렉토리 구조 | 패턴별로 별도의 디렉토리 생성하여 관련 모델, 메타데이터, 학습 기록 등 관리 |

## 3. 데이터 검증 기준

| 번호 | 검증 지표 | 설명 | 계산식/기준 |
|-----|----------|------|------------|
| 1 | 실루엣(Silhouette) | 클러스터링 품질 평가 지표로, 데이터가 얼마나 잘 군집화 되었는지 측정 | S = (b-a)/max(a,b)<br>S: 실루엣 점수<br>a: 같은 클러스터 내 데이터 간 평균 거리<br>b: 다른 클러스터와의 최소 평균 거리 |
| 2 | R2 Score | 회귀 모델의 설명력 지표로, 모델이 데이터 분산을 얼마나 잘 설명하는지 측정 | R² = 1 - (Σ(y_i - ŷ_i)²)/(Σ(y_i - ȳ)²)<br>y_i: 실제값<br>ŷ_i: 예측값<br>ȳ: 실제값의 평균<br>전체(ALL) 모델: 0.6 이상 |
| 3 | RMSE(Root Mean Square Error) | 예측값과 실제값의 차이를 측정하는 오차 지표 | RMSE = √(Σ(y_i - ŷ_i)²/n)<br>y_i: 실제값<br>ŷ_i: 예측값<br>n: 데이터 수 |
| 4 | Accuracy | 분류 모델의 정확도를 나타내는 지표 | 실제값과 예측값의 차이가 10% 이내<br>클러스터별 XGBoost 모델: 65% 이상 |
| 5 | 오토인코더 재구성 정확도 | 오토인코더가 입력 데이터를 얼마나 정확히 재구성하는지 측정 | 95% 이상의 재구성 정확도 (MSE 기준) |
| 6 | K-Fold 교차 검증 편차 | 교차 검증 간 성능 지표 편차로 모델 안정성 평가 | 5-Fold 교차 검증 시 R2 점수 표준편차가 0.1 이하 |
| 7 | 개인화 모델 향상도 | 개인화 모델이 파운데이션 모델 대비 성능 향상 정도 | 최소 5% 이상의 정확도 또는 R2 점수 향상 시 개인화 모델 채택 |
| 8 | 모델 버전 간 성능 차이 | 신규 모델 버전과 이전 버전 간의 성능 차이 | 최소 2% 이상의 성능 향상이 있을 때만 모델 업데이트 적용 |
| 9 | 패턴 분류 혼동 행렬 | 패턴 분류의 정확도를 평가하기 위한 혼동 행렬 | 대각선 요소(정확히 분류된 케이스)가 75% 이상 |
| 10 | Unknown 패턴 비율 | 어떤 패턴으로도 분류되지 않은 데이터 비율 | 전체 데이터의 5% 이하 |

## 4. 모델 활용 및 산출물

### 4.1 사용자 모델 활용 방안

| 단계 | 내용 | 설명 |
|-----|------|------|
| 1 | 분류기 완성 | 오토인코더 기반 분류기와 XGBoost 파운데이션 모델이 모든 검증 기준을 통과하면 최종 모델로 확정 |
| 2 | 신규 사용자 분류 | 신규 사용자의 패턴을 분석하여 기존 군집 중 가장 유사한 군집으로 분류 |
| 3 | 예측 모델 적용 | 분류된 군집에 해당하는 최적화된 XGBoost 모델을 사용하여 출수량 예측 |
| 4 | 추천 시스템 연계 | 군집별 특성에 기반한 맞춤형 추천 서비스 제공 |
| 5 | 이상 패턴 감지 | 기존 군집과 현저히 다른 패턴 발견 시 이상 사용 패턴으로 감지 |
| 6 | 개인화 모델 적용 | 충분한 데이터가 수집된 사용자에게는 개인화된 예측 모델 적용 |
| 7 | 지속적 모델 개선 | 7일 주기로 새로운 데이터를 반영하여 모델 개선 및 버전 관리 |
| 8 | 미할당 사용자 관리 | 기존 클러스터에 할당되지 않은 사용자들을 위한 신규 파운데이션 모델 개발 |

### 4.2 User Model 정확도 관리

| 항목 | 설명 | 기준 |
|-----|------|------|
| 모델 정확도 모니터링 | 사용자별 모델의 예측 정확도 지속적 모니터링 | 최소 예측 정확도 60% 이상 유지 |
| 패턴 변화 감지 | 사용자의 패턴 변화 감지 및 대응 | 패턴 변화율 15% 이상 시 모델 재학습 |
| 모델 성능 저하 감지 | 시간 경과에 따른 모델 성능 저하 감지 | 14일 연속 성능 저하 시 모델 재구축 |
| 정확도 보고서 | 정기적인 모델 정확도 보고서 생성 | 주간/월간 정확도 변화 추세 분석 |

### 4.3 주요 산출물

| 산출물 | 설명 | 주기적 업데이트 |
|--------|------|----------------|
| 군집별 패턴 프로파일 | 각 군집의 특성과 패턴을 요약한 프로파일 | 월 1회 |
| 사용자 모델 매핑 테이블 | 사용자와 할당된 모델 정보를 관리하는 테이블 | 일 1회 |
| 모델 성능 대시보드 | 모델 성능 지표를 시각화한 대시보드 | 실시간 |
| 이상 패턴 보고서 | 감지된 이상 패턴 분석 보고서 | 주 1회 |
| 모델 버전 히스토리 | 모델의 버전별 변경 이력 및 성능 변화 | 변경 시 |


